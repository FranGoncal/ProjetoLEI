{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6149307-44ee-4a9c-aea3-213417749f18",
   "metadata": {},
   "source": [
    "# Carregamento e Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d19ab0-1258-41f5-a69a-fdbcb976fca4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9910eddf-fb70-4944-94c3-7ce6f5629bf6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Dataset da IBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f0296ee7-22a9-466d-99e4-197026fd3426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Lendo o arquivo XLS\n",
    "df_IBM = pd.read_csv('data/WA_Fn-UseC_-Telco-Customer-Churn.xls')\n",
    "\n",
    "selected_columns = [\n",
    "    'tenure', \n",
    "    'MonthlyCharges', \n",
    "    'Contract', \n",
    "    'InternetService', \n",
    "    'TechSupport', \n",
    "    'Churn'\n",
    "]\n",
    "# Filtrar atributos do dataset\n",
    "df_IBM = df_IBM[selected_columns]\n",
    "\n",
    "# Nomear os atributos de maneira a serem compativeis entre datasets\n",
    "df_IBM = df_IBM.rename(columns={'tenure': 'Tenure'})\n",
    "df_IBM = df_IBM.rename(columns={'Contract': 'ContractType'})\n",
    "\n",
    "df_IBM['TechSupport'] = df_IBM['TechSupport'].replace('No internet service', 'No')\n",
    "df_IBM['InternetService'] = df_IBM['InternetService'].replace('Fiber optic', 'Fiber Optic')\n",
    "df_IBM['ContractType'] = df_IBM['ContractType'].replace('Month-to-month', 'Month-to-Month')\n",
    "df_IBM['ContractType'] = df_IBM['ContractType'].replace('Two year', 'Two-Year')\n",
    "df_IBM['ContractType'] = df_IBM['ContractType'].replace('One year', 'One-Year')\n",
    "\n",
    "\n",
    "# Tornar em binário os valores categoricos através do one-hot encoding\n",
    "df_IBM = pd.get_dummies(df_IBM, columns=['ContractType', 'InternetService'], drop_first=False, dtype=int)\n",
    "df_IBM = pd.get_dummies(df_IBM, columns=['TechSupport', 'Churn'], drop_first=True, dtype=int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86d21c9-f10e-40a3-ab74-a5deeb878e6b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "### Dataset Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0072b203-1d41-494d-8e70-8d7afa194d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/customer_churn_data.csv')\n",
    "\n",
    "selected_columns = [\n",
    "    'Tenure', \n",
    "    'MonthlyCharges', \n",
    "    'ContractType', \n",
    "    'InternetService', \n",
    "    'TechSupport', \n",
    "    'Churn'\n",
    "]\n",
    "# Filtrar atributos do dataset\n",
    "df = df[selected_columns]\n",
    "\n",
    "# Substituir os valores NaN por \"Nenhum\"\n",
    "df['InternetService'] = df['InternetService'].fillna('No')\n",
    "# Tornar em binário os valores categoricos através do one-hot encoding\n",
    "df = pd.get_dummies(df, columns=['ContractType', 'InternetService'], drop_first=False, dtype=int)\n",
    "df = pd.get_dummies(df, columns=[\"TechSupport\", \"Churn\"], drop_first=True, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a8155f-7acf-462d-8d02-24b4f2d9beb8",
   "metadata": {},
   "source": [
    "## Normalização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156b4427-2805-4253-9925-6c0ab4a69459",
   "metadata": {},
   "source": [
    "### Dataset da IBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11285b2d-d06c-4a1f-a904-76ac44009534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "columns_to_normalize = ['Tenure', 'MonthlyCharges']\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Normalizar colunas numéricas\n",
    "df_IBM[columns_to_normalize] = scaler.fit_transform(df_IBM[columns_to_normalize])\n",
    "\n",
    "# Preparação dos dados no formato de treino\n",
    "X_IBM = df_IBM.drop(columns=['Churn_Yes'])\n",
    "y_IBM = df_IBM['Churn_Yes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e1c4cd-27a6-4354-9c5a-924ca3780eb2",
   "metadata": {},
   "source": [
    "### Dataset Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bfd81018-b0d6-4b04-aacb-2d8d9993c8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "'''\n",
    "columns_to_normalize = [ 'Tenure', 'MonthlyCharges']\n",
    "\n",
    "# Normalizar colunas numéricas\n",
    "df[columns_to_normalize] = scaler.transform(df[columns_to_normalize])\n",
    "'''\n",
    "# Preparação dos dados no formato de treino\n",
    "X_kaggle = df.drop(columns=['Churn_Yes'])\n",
    "y_kaggle = df['Churn_Yes']\n",
    "\n",
    "# Reordenar o segundo dataset para ter a mesma ordem do primeiro\n",
    "df_IBM = df_IBM[df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6192ab-6f0e-4357-9afb-d61ffec16ac3",
   "metadata": {},
   "source": [
    "## Balanceamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "041aba71-dda4-46f2-beb3-79c93f44d434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n##Smote + Tomek\\nsmote = SMOTE(sampling_strategy='auto', random_state=42)\\ntomek = TomekLinks(sampling_strategy='majority')\\n\\nX_res_treino, y_res_treino = smote.fit_resample(X_treino, y_treino)\\nX_res_treino, y_res_treino = tomek.fit_resample(X_res_treino, y_res_treino)\\n\\nX_res_test, y_res_test = smote.fit_resample(X_test, y_test)\\nX_res_test, y_res_test = tomek.fit_resample(X_res_test, y_res_test)\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "'''\n",
    "##Smote + Tomek\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "tomek = TomekLinks(sampling_strategy='majority')\n",
    "\n",
    "X_res_treino, y_res_treino = smote.fit_resample(X_treino, y_treino)\n",
    "X_res_treino, y_res_treino = tomek.fit_resample(X_res_treino, y_res_treino)\n",
    "\n",
    "X_res_test, y_res_test = smote.fit_resample(X_test, y_test)\n",
    "X_res_test, y_res_test = tomek.fit_resample(X_res_test, y_res_test)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd45ef92-a7be-4778-b0d4-52f0d6f3cbe5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Treino e Avaliação Treino: IBM / Teste: Kaggle (OVERSAMPLING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3640fab7-729a-4934-844b-b26996c5a911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn_Yes\n",
      "0    5174\n",
      "1    5174\n",
      "Name: count, dtype: int64\n",
      "Churn_Yes\n",
      "1    883\n",
      "0    117\n",
      "Name: count, dtype: int64\n",
      "{0, 1}\n",
      "{0, 1}\n",
      "{0, 1}\n",
      "{0, 1}\n",
      "{0, 1}\n",
      "{0}\n",
      "         Precision  Accuracy  Recall  F1 Score    AUC\n",
      "RF           0.638     0.149   0.084     0.148  0.377\n",
      "SVM          1.000     0.470   0.400     0.540  0.525\n",
      "XGBoost      1.000     0.316   0.225     0.355  0.761\n",
      "DT           0.664     0.158   0.094     0.163  0.368\n",
      "LR           0.927     0.760   0.790     0.793  0.766\n",
      "NB           0.000     0.117   0.000     0.025  0.513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from scipy.integrate import trapezoid\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, recall_score, roc_curve, precision_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# treino IBM -> test Kaggle\n",
    "\n",
    "X_treino = X_IBM.copy()\n",
    "y_treino = y_IBM.copy()\n",
    "\n",
    "X_test = X_kaggle.copy()\n",
    "y_test = y_kaggle.copy()\n",
    "\n",
    "#normalização\n",
    "columns_to_normalize = ['Tenure', 'MonthlyCharges']\n",
    "scaler = StandardScaler()\n",
    "X_treino[columns_to_normalize] = scaler.fit_transform(X_treino[columns_to_normalize])\n",
    "X_test[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "#Balanceamento \n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "#tomek = TomekLinks(sampling_strategy='majority')\n",
    "\n",
    "X_res_treino, y_res_treino = smote.fit_resample(X_treino, y_treino)\n",
    "#X_res_treino, y_res_treino = tomek.fit_resample(X_res_treino, y_res_treino)\n",
    "\n",
    "y_res_test = y_test\n",
    "X_res_test = X_test\n",
    "\n",
    "#X_res_test, y_res_test = smote.fit_resample(X_test, y_test)\n",
    "#X_res_test, y_res_test = tomek.fit_resample(X_res_test, y_res_test)\n",
    "\n",
    "print(y_res_treino.value_counts())\n",
    "print(y_res_test.value_counts())\n",
    "\n",
    "\n",
    "# Modelos de Classificação\n",
    "classifiers = {\n",
    "    \"RF\": RandomForestClassifier(random_state=42),\n",
    "    \"SVM\": SVC(kernel='linear', random_state=42, probability=True),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42, n_estimators=3, max_depth=2, learning_rate=1, objective='binary:logistic'),\n",
    "    \"DT\": DecisionTreeClassifier(random_state=42),\n",
    "    \"LR\": LogisticRegression(random_state=42, max_iter=1000),\n",
    "    \"NB\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Resultados\n",
    "results = {}\n",
    "\n",
    "# Avaliar Classificação\n",
    "for name, model in classifiers.items():\n",
    "    # Treinar com o primeiro dataset\n",
    "    model.fit(X_res_treino, y_res_treino)\n",
    "    \n",
    "    # Avaliar com o segundo dataset\n",
    "    predictions = model.predict(X_res_test)\n",
    "    print(set(predictions))\n",
    "    predictions_prob = model.predict_proba(X_res_test)[:, 1]  # Probabilidades para calcular AUC\n",
    "\n",
    "    # Calcular as métricas\n",
    "    f1 = f1_score(y_res_test, predictions, average='weighted')\n",
    "    auc = roc_auc_score(y_res_test, predictions_prob)\n",
    "    accuracy = accuracy_score(y_res_test, predictions)\n",
    "    recall = recall_score(y_res_test, predictions)\n",
    "    precision = precision_score(y_res_test, predictions)  #?, zero_division=1\n",
    "\n",
    "     # Calcular a curva ROC\n",
    "    fpr, tpr, thresholds = roc_curve(y_res_test, predictions_prob)  # FPR e TPR para calcular a curva ROC\n",
    "    roc = trapezoid(tpr, fpr)  # Calculando a área sob a curva ROC (AUC)\n",
    "    \n",
    "    # Armazenar os resultados\n",
    "    results[name] = {\n",
    "        \"Precision\": precision,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        \"AUC\": auc\n",
    "    }\n",
    "    \n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.round(3)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a9b777-443c-42f6-a060-02031e4cc0d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Treino e Avaliação Treino: IBM / Teste: Kaggle (UNDERSAMPLING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bb5eb365-0d48-4f94-85d8-4754d4a6bd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn_Yes\n",
      "0    1869\n",
      "1    1869\n",
      "Name: count, dtype: int64\n",
      "Churn_Yes\n",
      "1    883\n",
      "0    117\n",
      "Name: count, dtype: int64\n",
      "Contagem das previsões da classe 1:  101\n",
      "Contagem das previsões da classe 1:  353\n",
      "Contagem das previsões da classe 1:  199\n",
      "Contagem das previsões da classe 1:  272\n",
      "Contagem das previsões da classe 1:  719\n",
      "Contagem das previsões da classe 1:  0\n",
      "         Precision  Accuracy  Recall  F1 Score    AUC\n",
      "RF           0.584     0.134   0.067     0.123  0.386\n",
      "SVM          1.000     0.470   0.400     0.540  0.732\n",
      "XGBoost      1.000     0.316   0.225     0.355  0.655\n",
      "DT           0.846     0.305   0.260     0.372  0.451\n",
      "LR           0.929     0.734   0.757     0.775  0.769\n",
      "NB           0.000     0.117   0.000     0.025  0.516\n"
     ]
    }
   ],
   "source": [
    "from scipy.integrate import trapezoid\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, recall_score, roc_curve, precision_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# treino IBM -> test Kaggle\n",
    "\n",
    "X_treino = X_IBM.copy()\n",
    "y_treino = y_IBM.copy()\n",
    "\n",
    "X_test = X_kaggle.copy()\n",
    "y_test = y_kaggle.copy()\n",
    "\n",
    "#normalização\n",
    "columns_to_normalize = ['Tenure', 'MonthlyCharges']\n",
    "scaler = StandardScaler()\n",
    "X_treino[columns_to_normalize] = scaler.fit_transform(X_treino[columns_to_normalize])\n",
    "X_test[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "#Balanceamento undersampling\n",
    "undersampler = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "X_res_treino, y_res_treino = undersampler.fit_resample(X_treino, y_treino)\n",
    "\n",
    "y_res_test = y_test\n",
    "X_res_test = X_test\n",
    "#X_res_test, y_res_test = smote.fit_resample(X_test, y_test)\n",
    "#X_res_test, y_res_test = tomek.fit_resample(X_res_test, y_res_test)\n",
    "\n",
    "print(y_res_treino.value_counts())\n",
    "print(y_res_test.value_counts())\n",
    "\n",
    "\n",
    "# Modelos de Classificação\n",
    "classifiers = {\n",
    "    \"RF\": RandomForestClassifier(random_state=42),\n",
    "    \"SVM\": SVC(kernel='linear', random_state=42, probability=True),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42, n_estimators=3, max_depth=2, learning_rate=1, objective='binary:logistic'),\n",
    "    \"DT\": DecisionTreeClassifier(random_state=42),\n",
    "    \"LR\": LogisticRegression(random_state=42, max_iter=1000),\n",
    "    \"NB\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Resultados\n",
    "results = {}\n",
    "\n",
    "# Avaliar Classificação\n",
    "for name, model in classifiers.items():\n",
    "    # Treinar com o primeiro dataset\n",
    "    model.fit(X_res_treino, y_res_treino)\n",
    "    \n",
    "    # Avaliar com o segundo dataset\n",
    "    predictions = model.predict(X_res_test)\n",
    "    #print(set(predictions))\n",
    "    #print(\"Previsões: \", predictions)\n",
    "    print(\"Contagem das previsões da classe 1: \", sum(predictions == 1))\n",
    "    predictions_prob = model.predict_proba(X_res_test)[:, 1]  # Probabilidades para calcular AUC\n",
    "\n",
    "    # Calcular as métricas\n",
    "    f1 = f1_score(y_res_test, predictions, average='weighted')\n",
    "    auc = roc_auc_score(y_res_test, predictions_prob)\n",
    "    accuracy = accuracy_score(y_res_test, predictions)\n",
    "    recall = recall_score(y_res_test, predictions)\n",
    "    precision = precision_score(y_res_test, predictions, zero_division=0)  #?\n",
    "\n",
    "     # Calcular a curva ROC\n",
    "    fpr, tpr, thresholds = roc_curve(y_res_test, predictions_prob)  # FPR e TPR para calcular a curva ROC\n",
    "    roc = trapezoid(tpr, fpr)  # Calculando a área sob a curva ROC (AUC)\n",
    "    \n",
    "    # Armazenar os resultados\n",
    "    results[name] = {\n",
    "        \"Precision\": precision,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        \"AUC\": auc\n",
    "    }\n",
    "    \n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.round(3)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d21dbe-1493-499d-81e3-9436304d7c84",
   "metadata": {},
   "source": [
    "# Treino e Avaliação Treino: Kaggle / Teste: IBM (OVERSAMPLING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "23ceb81f-9522-463a-8487-4c0e5e55ecef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn_Yes\n",
      "1    610\n",
      "0    610\n",
      "Name: count, dtype: int64\n",
      "Churn_Yes\n",
      "0    508\n",
      "1    192\n",
      "Name: count, dtype: int64\n",
      "         Precision  Accuracy  Recall  F1 Score    AUC\n",
      "RF           0.274     0.274   1.000     0.118  0.560\n",
      "SVM          0.285     0.326   0.969     0.231  0.677\n",
      "XGBoost      0.274     0.274   1.000     0.118  0.463\n",
      "DT           0.274     0.274   1.000     0.118  0.500\n",
      "LR           0.323     0.439   0.953     0.413  0.752\n",
      "NB           0.323     0.439   0.953     0.413  0.598\n"
     ]
    }
   ],
   "source": [
    "from scipy.integrate import trapezoid\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, recall_score, roc_curve, precision_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "# treino Kaggle -> test IBM\n",
    "\n",
    "X_treino = X_kaggle.copy()\n",
    "y_treino = y_kaggle.copy()\n",
    "\n",
    "X_test = X_IBM.copy()\n",
    "y_test = y_IBM.copy()\n",
    "\n",
    "#redução\n",
    "X_treino = X_treino.sample(n=700, random_state=42)\n",
    "y_treino = y_treino[X_treino.index]\n",
    "\n",
    "X_test = X_test.sample(n=700, random_state=42)\n",
    "y_test = y_test[X_test.index]\n",
    "\n",
    "#normalização\n",
    "columns_to_normalize = ['Tenure', 'MonthlyCharges']\n",
    "scaler = StandardScaler()\n",
    "X_treino[columns_to_normalize] = scaler.fit_transform(X_treino[columns_to_normalize])\n",
    "X_test[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "#Balanceamento \n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "tomek = TomekLinks(sampling_strategy='majority')\n",
    "\n",
    "X_res_treino, y_res_treino = smote.fit_resample(X_treino, y_treino)\n",
    "#X_res_treino, y_res_treino = tomek.fit_resample(X_res_treino, y_res_treino)\n",
    "\n",
    "X_res_test = X_test\n",
    "y_res_test = y_test\n",
    "\n",
    "#X_res_test, y_res_test = smote.fit_resample(X_test, y_test)\n",
    "#X_res_test, y_res_test = tomek.fit_resample(X_res_test, y_res_test)\n",
    "\n",
    "print(y_res_treino.value_counts())\n",
    "print(y_res_test.value_counts())\n",
    "\n",
    "# Modelos de Classificação\n",
    "classifiers = {\n",
    "    \"RF\": RandomForestClassifier(random_state=42),\n",
    "    \"SVM\": SVC(kernel='linear', random_state=42, probability=True),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42, n_estimators=3, max_depth=2, learning_rate=1, objective='binary:logistic'),\n",
    "    \"DT\": DecisionTreeClassifier(random_state=42),\n",
    "    \"LR\": LogisticRegression(random_state=42, max_iter=1000),\n",
    "    \"NB\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Resultados\n",
    "results = {}\n",
    "\n",
    "# Avaliar Classificação\n",
    "for name, model in classifiers.items():\n",
    "    # Treinar com o primeiro dataset\n",
    "    model.fit(X_res_treino, y_res_treino)\n",
    "    \n",
    "    # Avaliar com o segundo dataset\n",
    "    predictions = model.predict(X_res_test)\n",
    "    predictions_prob = model.predict_proba(X_res_test)[:, 1]  # Probabilidades para calcular AUC\n",
    "\n",
    "    # Calcular as métricas\n",
    "    f1 = f1_score(y_res_test, predictions, average='weighted')\n",
    "    auc = roc_auc_score(y_res_test, predictions_prob)\n",
    "    accuracy = accuracy_score(y_res_test, predictions)\n",
    "    recall = recall_score(y_res_test, predictions)\n",
    "    precision = precision_score(y_res_test, predictions)\n",
    "\n",
    "     # Calcular a curva ROC\n",
    "    fpr, tpr, thresholds = roc_curve(y_res_test, predictions_prob)\n",
    "    roc = trapezoid(tpr, fpr)\n",
    "    \n",
    "    # Armazenar os resultados\n",
    "    results[name] = {\n",
    "        \"Precision\": precision,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        \"AUC\": auc\n",
    "    }\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.round(3)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8f3e90-2c29-4b5c-ae01-939e92bec692",
   "metadata": {},
   "source": [
    "# Treino e Avaliação Treino: Kaggle / Teste: IBM (UNDERSAMPLING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ef15ee29-ab48-4db8-92a1-a951385dc81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn_Yes\n",
      "0    90\n",
      "1    90\n",
      "Name: count, dtype: int64\n",
      "Churn_Yes\n",
      "0    508\n",
      "1    192\n",
      "Name: count, dtype: int64\n",
      "         Precision  Accuracy  Recall  F1 Score    AUC\n",
      "RF           0.274     0.274   1.000     0.118  0.664\n",
      "SVM          0.323     0.439   0.953     0.413  0.711\n",
      "XGBoost      0.274     0.274   1.000     0.118  0.580\n",
      "DT           0.274     0.274   1.000     0.118  0.500\n",
      "LR           0.331     0.466   0.927     0.454  0.715\n",
      "NB           0.323     0.439   0.953     0.413  0.596\n"
     ]
    }
   ],
   "source": [
    "from scipy.integrate import trapezoid\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, recall_score, roc_curve, precision_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "# treino Kaggle -> test IBM\n",
    "\n",
    "X_treino = X_kaggle.copy()\n",
    "y_treino = y_kaggle.copy()\n",
    "\n",
    "X_test = X_IBM.copy()\n",
    "y_test = y_IBM.copy()\n",
    "\n",
    "#Redução\n",
    "X_treino = X_treino.sample(n=700, random_state=42)\n",
    "y_treino = y_treino[X_treino.index]\n",
    "\n",
    "X_test = X_test.sample(n=700, random_state=42)\n",
    "y_test = y_test[X_test.index]\n",
    "\n",
    "#normalização\n",
    "columns_to_normalize = ['Tenure', 'MonthlyCharges']\n",
    "scaler = StandardScaler()\n",
    "X_treino[columns_to_normalize] = scaler.fit_transform(X_treino[columns_to_normalize])\n",
    "X_test[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "#Balanceamento \n",
    "undersampler = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "X_res_treino, y_res_treino = undersampler.fit_resample(X_treino, y_treino)\n",
    "\n",
    "X_res_test = X_test\n",
    "y_res_test = y_test\n",
    "\n",
    "#X_res_test = X_test.sample(n=100, random_state=42)\n",
    "#y_res_test = y_test[X_res_test.index]\n",
    "\n",
    "\n",
    "#X_res_test, y_res_test = smote.fit_resample(X_test, y_test)\n",
    "#X_res_test, y_res_test = tomek.fit_resample(X_res_test, y_res_test)\n",
    "\n",
    "print(y_res_treino.value_counts())\n",
    "print(y_res_test.value_counts())\n",
    "\n",
    "# Modelos de Classificação\n",
    "classifiers = {\n",
    "    \"RF\": RandomForestClassifier(random_state=42),\n",
    "    \"SVM\": SVC(kernel='linear', random_state=42, probability=True),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42, n_estimators=3, max_depth=2, learning_rate=1, objective='binary:logistic'),\n",
    "    \"DT\": DecisionTreeClassifier(random_state=42),\n",
    "    \"LR\": LogisticRegression(random_state=42, max_iter=1000),\n",
    "    \"NB\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Resultados\n",
    "results = {}\n",
    "\n",
    "# Avaliar Classificação\n",
    "for name, model in classifiers.items():\n",
    "    # Treinar com o primeiro dataset\n",
    "    model.fit(X_res_treino, y_res_treino)\n",
    "    \n",
    "    # Avaliar com o segundo dataset\n",
    "    predictions = model.predict(X_res_test)\n",
    "    predictions_prob = model.predict_proba(X_res_test)[:, 1]  # Probabilidades para calcular AUC\n",
    "\n",
    "    # Calcular as métricas\n",
    "    f1 = f1_score(y_res_test, predictions, average='weighted')\n",
    "    auc = roc_auc_score(y_res_test, predictions_prob)\n",
    "    accuracy = accuracy_score(y_res_test, predictions)\n",
    "    recall = recall_score(y_res_test, predictions)\n",
    "    precision = precision_score(y_res_test, predictions)\n",
    "\n",
    "     # Calcular a curva ROC\n",
    "    fpr, tpr, thresholds = roc_curve(y_res_test, predictions_prob)\n",
    "    roc = trapezoid(tpr, fpr)\n",
    "    \n",
    "    # Armazenar os resultados\n",
    "    results[name] = {\n",
    "        \"Precision\": precision,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        \"AUC\": auc\n",
    "    }\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.round(3)\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
