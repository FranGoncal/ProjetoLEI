{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6149307-44ee-4a9c-aea3-213417749f18",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Carregamento e Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d19ab0-1258-41f5-a69a-fdbcb976fca4",
   "metadata": {},
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9910eddf-fb70-4944-94c3-7ce6f5629bf6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Dataset da IBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0296ee7-22a9-466d-99e4-197026fd3426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Lendo o arquivo XLS\n",
    "df_IBM = pd.read_csv('data/WA_Fn-UseC_-Telco-Customer-Churn.xls')\n",
    "\n",
    "selected_columns = [\n",
    "    'tenure', \n",
    "    'MonthlyCharges', \n",
    "    'Contract', \n",
    "    'InternetService', \n",
    "    'TechSupport', \n",
    "    'Churn'\n",
    "]\n",
    "# Filtrar atributos do dataset\n",
    "df_IBM = df_IBM[selected_columns]\n",
    "\n",
    "# Nomear os atributos de maneira a serem compativeis entre datasets\n",
    "df_IBM = df_IBM.rename(columns={'tenure': 'Tenure'})\n",
    "df_IBM = df_IBM.rename(columns={'Contract': 'ContractType'})\n",
    "\n",
    "df_IBM['TechSupport'] = df_IBM['TechSupport'].replace('No internet service', 'No')\n",
    "df_IBM['InternetService'] = df_IBM['InternetService'].replace('Fiber optic', 'Fiber Optic')\n",
    "df_IBM['ContractType'] = df_IBM['ContractType'].replace('Month-to-month', 'Month-to-Month')\n",
    "df_IBM['ContractType'] = df_IBM['ContractType'].replace('Two year', 'Two-Year')\n",
    "df_IBM['ContractType'] = df_IBM['ContractType'].replace('One year', 'One-Year')\n",
    "\n",
    "\n",
    "# Tornar em binário os valores categoricos através do one-hot encoding\n",
    "df_IBM = pd.get_dummies(df_IBM, columns=['ContractType', 'InternetService'], drop_first=False, dtype=int)\n",
    "df_IBM = pd.get_dummies(df_IBM, columns=['TechSupport', 'Churn'], drop_first=True, dtype=int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86d21c9-f10e-40a3-ab74-a5deeb878e6b",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0072b203-1d41-494d-8e70-8d7afa194d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/customer_churn_data.csv')\n",
    "\n",
    "selected_columns = [\n",
    "    'Tenure', \n",
    "    'MonthlyCharges', \n",
    "    'ContractType', \n",
    "    'InternetService', \n",
    "    'TechSupport', \n",
    "    'Churn'\n",
    "]\n",
    "# Filtrar atributos do dataset\n",
    "df = df[selected_columns]\n",
    "\n",
    "# Substituir os valores NaN por \"Nenhum\"\n",
    "df['InternetService'] = df['InternetService'].fillna('No')\n",
    "# Tornar em binário os valores categoricos através do one-hot encoding\n",
    "df = pd.get_dummies(df, columns=['ContractType', 'InternetService'], drop_first=False, dtype=int)\n",
    "df = pd.get_dummies(df, columns=[\"TechSupport\", \"Churn\"], drop_first=True, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a8155f-7acf-462d-8d02-24b4f2d9beb8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Normalização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156b4427-2805-4253-9925-6c0ab4a69459",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Dataset da IBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11285b2d-d06c-4a1f-a904-76ac44009534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "columns_to_normalize = ['Tenure', 'MonthlyCharges']\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Normalizar colunas numéricas\n",
    "df_IBM[columns_to_normalize] = scaler.fit_transform(df_IBM[columns_to_normalize])\n",
    "\n",
    "# Preparação dos dados no formato de treino\n",
    "X_treino = df_IBM.drop(columns=['Churn_Yes'])\n",
    "y_treino = df_IBM['Churn_Yes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e1c4cd-27a6-4354-9c5a-924ca3780eb2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Dataset Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfd81018-b0d6-4b04-aacb-2d8d9993c8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "columns_to_normalize = [ 'Tenure', 'MonthlyCharges']\n",
    "\n",
    "# Normalizar colunas numéricas\n",
    "df[columns_to_normalize] = scaler.transform(df[columns_to_normalize])\n",
    "\n",
    "# Preparação dos dados no formato de treino\n",
    "X_test = df.drop(columns=['Churn_Yes'])\n",
    "y_test = df['Churn_Yes']\n",
    "\n",
    "# Reordenar o segundo dataset para ter a mesma ordem do primeiro\n",
    "df_IBM = df_IBM[df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6192ab-6f0e-4357-9afb-d61ffec16ac3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Balanceamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "041aba71-dda4-46f2-beb3-79c93f44d434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import numpy as np\n",
    "\n",
    "undersampler = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "X_res_treino, y_res_treino = undersampler.fit_resample(X_treino, y_treino)\n",
    "X_res_test, y_res_test = undersampler.fit_resample(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd45ef92-a7be-4778-b0d4-52f0d6f3cbe5",
   "metadata": {},
   "source": [
    "# Treino e Avaliação Treino: IBM / Teste: Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3640fab7-729a-4934-844b-b26996c5a911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Precision  Accuracy  Recall  F1 Score    AUC\n",
      "RF           0.833     0.620   0.299     0.576  0.705\n",
      "SVM          1.000     0.748   0.496     0.731  0.853\n",
      "XGBoost      1.000     0.679   0.359     0.643  0.789\n",
      "DT           0.459     0.470   0.333     0.460  0.470\n",
      "LR           0.890     0.744   0.556     0.734  0.834\n",
      "NB           1.000     0.748   0.496     0.731  0.830\n"
     ]
    }
   ],
   "source": [
    "from scipy.integrate import trapezoid\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, recall_score, roc_curve, precision_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# treino IBM -> test Kaggle\n",
    "\n",
    "\n",
    "# Modelos de Classificação\n",
    "classifiers = {\n",
    "    \"RF\": RandomForestClassifier(random_state=42),\n",
    "    \"SVM\": SVC(kernel='linear', random_state=42, probability=True),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42, n_estimators=3, max_depth=2, learning_rate=1, objective='binary:logistic'),\n",
    "    \"DT\": DecisionTreeClassifier(random_state=42),\n",
    "    \"LR\": LogisticRegression(random_state=42, max_iter=1000),\n",
    "    \"NB\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Resultados\n",
    "results = {}\n",
    "\n",
    "# Avaliar Classificação\n",
    "for name, model in classifiers.items():\n",
    "    # Treinar com o primeiro dataset\n",
    "    model.fit(X_res_treino, y_res_treino)\n",
    "    \n",
    "    # Avaliar com o segundo dataset\n",
    "    predictions = model.predict(X_res_test)\n",
    "    predictions_prob = model.predict_proba(X_res_test)[:, 1]  # Probabilidades para calcular AUC\n",
    "\n",
    "    # Calcular as métricas\n",
    "    f1 = f1_score(y_res_test, predictions, average='weighted')\n",
    "    auc = roc_auc_score(y_res_test, predictions_prob)\n",
    "    accuracy = accuracy_score(y_res_test, predictions)\n",
    "    recall = recall_score(y_res_test, predictions)\n",
    "    precision = precision_score(y_res_test, predictions)\n",
    "\n",
    "     # Calcular a curva ROC\n",
    "    fpr, tpr, thresholds = roc_curve(y_res_test, predictions_prob)  # FPR e TPR para calcular a curva ROC\n",
    "    roc = trapezoid(tpr, fpr)  # Calculando a área sob a curva ROC (AUC)\n",
    "    \n",
    "    # Armazenar os resultados\n",
    "    results[name] = {\n",
    "        \"Precision\": precision,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        \"AUC\": auc\n",
    "    }\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.round(3)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d21dbe-1493-499d-81e3-9436304d7c84",
   "metadata": {},
   "source": [
    "# Treino e Avaliação Treino: Kaggle / Teste: IBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23ceb81f-9522-463a-8487-4c0e5e55ecef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Precision  Accuracy  Recall  F1 Score    AUC\n",
      "RF           0.544     0.579   0.973     0.501  0.726\n",
      "SVM          0.560     0.601   0.944     0.547  0.770\n",
      "XGBoost      0.558     0.598   0.945     0.543  0.732\n",
      "DT           0.544     0.578   0.973     0.500  0.578\n",
      "LR           0.616     0.673   0.922     0.652  0.796\n",
      "NB           0.560     0.601   0.944     0.547  0.604\n"
     ]
    }
   ],
   "source": [
    "from scipy.integrate import trapezoid\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, recall_score, roc_curve, precision_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "# treino Kaggle -> test IBM\n",
    "x_aux = X_res_treino\n",
    "y_aux = y_res_treino\n",
    "X_res_treino = X_res_test\n",
    "y_res_treino = y_res_test\n",
    "X_res_test = x_aux\n",
    "y_res_test = y_aux\n",
    "\n",
    "\n",
    "# Modelos de Classificação\n",
    "classifiers = {\n",
    "    \"RF\": RandomForestClassifier(random_state=42),\n",
    "    \"SVM\": SVC(kernel='linear', random_state=42, probability=True),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42, n_estimators=3, max_depth=2, learning_rate=1, objective='binary:logistic'),\n",
    "    \"DT\": DecisionTreeClassifier(random_state=42),\n",
    "    \"LR\": LogisticRegression(random_state=42, max_iter=1000),\n",
    "    \"NB\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Resultados\n",
    "results = {}\n",
    "\n",
    "# Avaliar Classificação\n",
    "for name, model in classifiers.items():\n",
    "    # Treinar com o primeiro dataset\n",
    "    model.fit(X_res_treino, y_res_treino)\n",
    "    \n",
    "    # Avaliar com o segundo dataset\n",
    "    predictions = model.predict(X_res_test)\n",
    "    predictions_prob = model.predict_proba(X_res_test)[:, 1]  # Probabilidades para calcular AUC\n",
    "\n",
    "    # Calcular as métricas\n",
    "    f1 = f1_score(y_res_test, predictions, average='weighted')\n",
    "    auc = roc_auc_score(y_res_test, predictions_prob)\n",
    "    accuracy = accuracy_score(y_res_test, predictions)\n",
    "    recall = recall_score(y_res_test, predictions)\n",
    "    precision = precision_score(y_res_test, predictions)\n",
    "\n",
    "     # Calcular a curva ROC\n",
    "    fpr, tpr, thresholds = roc_curve(y_res_test, predictions_prob)\n",
    "    roc = trapezoid(tpr, fpr)\n",
    "    \n",
    "    # Armazenar os resultados\n",
    "    results[name] = {\n",
    "        \"Precision\": precision,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        \"AUC\": auc\n",
    "    }\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.round(3)\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
