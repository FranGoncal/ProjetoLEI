{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7f7202d-2d67-47bc-961b-78899bc36193",
   "metadata": {},
   "source": [
    "# IBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f44aec16-ecd3-463a-83ad-b7bd3dc34938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Lendo o arquivo XLS\n",
    "df_IBM = pd.read_csv('data/WA_Fn-UseC_-Telco-Customer-Churn.xls')\n",
    "\n",
    "selected_columns = [\n",
    "    'tenure', \n",
    "    'MonthlyCharges', \n",
    "    'Contract', \n",
    "    'InternetService', \n",
    "    'TechSupport', \n",
    "    'Churn'\n",
    "]\n",
    "# Filtrar atributos do dataset\n",
    "df_IBM = df_IBM[selected_columns]\n",
    "\n",
    "# Nomear os atributos de maneira a serem compativeis entre datasets\n",
    "df_IBM = df_IBM.rename(columns={'tenure': 'Tenure'})\n",
    "df_IBM = df_IBM.rename(columns={'Contract': 'ContractType'})\n",
    "\n",
    "df_IBM['TechSupport'] = df_IBM['TechSupport'].replace('No internet service', 'No')\n",
    "df_IBM['InternetService'] = df_IBM['InternetService'].replace('Fiber optic', 'Fiber Optic')\n",
    "df_IBM['ContractType'] = df_IBM['ContractType'].replace('Month-to-month', 'Month-to-Month')\n",
    "df_IBM['ContractType'] = df_IBM['ContractType'].replace('Two year', 'Two-Year')\n",
    "df_IBM['ContractType'] = df_IBM['ContractType'].replace('One year', 'One-Year')\n",
    "\n",
    "\n",
    "# Tornar em binário os valores categoricos através do one-hot encoding\n",
    "df_IBM = pd.get_dummies(df_IBM, columns=['ContractType', 'InternetService'], drop_first=False, dtype=int)\n",
    "df_IBM = pd.get_dummies(df_IBM, columns=['TechSupport', 'Churn'], drop_first=True, dtype=int)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "columns_to_normalize = ['Tenure', 'MonthlyCharges']\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Normalizar colunas numéricas\n",
    "df_IBM[columns_to_normalize] = scaler.fit_transform(df_IBM[columns_to_normalize])\n",
    "\n",
    "# Preparação dos dados no formato de treino\n",
    "X_ibm = df_IBM.drop(columns=['Churn_Yes'])\n",
    "y_ibm = df_IBM['Churn_Yes']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bd730d-bd77-46cf-a6f3-14fd7566a297",
   "metadata": {},
   "source": [
    "# Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "480c17cb-ff4e-4eda-8ba0-573c1b896330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/customer_churn_data.csv')\n",
    "\n",
    "selected_columns = [\n",
    "    'Tenure', \n",
    "    'MonthlyCharges', \n",
    "    'ContractType', \n",
    "    'InternetService', \n",
    "    'TechSupport', \n",
    "    'Churn'\n",
    "]\n",
    "# Filtrar atributos do dataset\n",
    "df = df[selected_columns]\n",
    "\n",
    "# Substituir os valores NaN por \"Nenhum\"\n",
    "df['InternetService'] = df['InternetService'].fillna('No')\n",
    "# Tornar em binário os valores categoricos através do one-hot encoding\n",
    "df = pd.get_dummies(df, columns=['ContractType', 'InternetService'], drop_first=False, dtype=int)\n",
    "df = pd.get_dummies(df, columns=[\"TechSupport\", \"Churn\"], drop_first=True, dtype=int)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "columns_to_normalize = [ 'Tenure', 'MonthlyCharges']\n",
    "\n",
    "# Normalizar colunas numéricas\n",
    "df[columns_to_normalize] = scaler.transform(df[columns_to_normalize])\n",
    "\n",
    "# Preparação dos dados no formato de treino\n",
    "X_test = df.drop(columns=['Churn_Yes'])\n",
    "y_test = df['Churn_Yes']\n",
    "\n",
    "# Reordenar o segundo dataset para ter a mesma ordem do primeiro\n",
    "df_IBM = df_IBM[df.columns]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "columns_to_normalize = [ 'Tenure', 'MonthlyCharges']\n",
    "\n",
    "# Normalizar colunas numéricas\n",
    "df[columns_to_normalize] = scaler.transform(df[columns_to_normalize])\n",
    "\n",
    "# Preparação dos dados no formato de treino\n",
    "X_kaggle = df.drop(columns=['Churn_Yes'])\n",
    "y_kaggle = df['Churn_Yes']\n",
    "\n",
    "# Reordenar o segundo dataset para ter a mesma ordem do primeiro\n",
    "df_IBM = df_IBM[df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3583f99f-72ad-4a5a-9004-d27e26e4acae",
   "metadata": {},
   "source": [
    "# Treino e Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ec39056-4b65-40b2-9ec3-2dbdede7e9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_validate\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#X=X_ibm\n",
    "#y=y_ibm\n",
    "\n",
    "#X=X_kaggle\n",
    "#y=y_kaggle\n",
    "\n",
    "X = pd.concat([X_ibm, X_kaggle], axis=0, ignore_index=True)\n",
    "y = pd.concat([y_ibm, y_kaggle], axis=0, ignore_index=True)\n",
    "\n",
    "# Configurar a validação cruzada\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "# Modelos de Classificação\n",
    "classifiers = {\n",
    "    \"RF\": RandomForestClassifier(random_state=42),\n",
    "    \"SVM\": SVC(kernel='linear', random_state=42, probability=True),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42, n_estimators=200, max_depth=10, learning_rate=1, objective='binary:logistic'),\n",
    "    \"DT\": DecisionTreeClassifier(random_state=42),\n",
    "    \"LR\": LogisticRegression(random_state=42, max_iter=1000),\n",
    "    \"NB\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Resultados\n",
    "results = {}\n",
    "\n",
    "# Avaliar Classificação com validação cruzada\n",
    "for name, model in classifiers.items():\n",
    "    cv_results = cross_validate(model, X, y, cv=cv,\n",
    "                                scoring=['accuracy', 'precision', 'f1_weighted', 'roc_auc', 'recall'],\n",
    "                                return_train_score=False)\n",
    "    \n",
    "    results[name] = {\n",
    "        \"Precision Mean\": np.mean(cv_results['test_precision']),\n",
    "        \"Precision Std\": np.std(cv_results['test_precision']),\n",
    "        \"Accuracy Mean\": np.mean(cv_results['test_accuracy']),\n",
    "        \"Accuracy Std\": np.std(cv_results['test_accuracy']),\n",
    "        \"Recall Mean\": np.mean(cv_results['test_recall']),\n",
    "        \"Recall Std\": np.std(cv_results['test_recall']),\n",
    "        \"F1 Score Mean\": np.mean(cv_results['test_f1_weighted']),\n",
    "        \"F1 Score Std\": np.std(cv_results['test_f1_weighted']),\n",
    "        \"AUC Mean\": np.mean(cv_results['test_roc_auc']),\n",
    "        \"AUC Std\": np.std(cv_results['test_roc_auc']),\n",
    "        \n",
    "    }\n",
    "\n",
    "# Converter os resultados num DataFrame\n",
    "results_df = pd.DataFrame(results).T  # Transpor para ter os modelos como linhas\n",
    "results_df = results_df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c8f3fea-91d5-41f6-a427-5bc3443497d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados:\n",
      "         Precision Mean  Precision Std  Accuracy Mean  Accuracy Std  \\\n",
      "RF               0.7212         0.0297         0.7941        0.0109   \n",
      "SVM              0.6921         0.0211         0.7664        0.0189   \n",
      "XGBoost          0.6897         0.0280         0.7828        0.0139   \n",
      "DT               0.6584         0.0286         0.7658        0.0147   \n",
      "LR               0.7068         0.0238         0.7815        0.0182   \n",
      "NB               0.5305         0.0270         0.6885        0.0171   \n",
      "\n",
      "         Recall Mean  Recall Std  F1 Score Mean  F1 Score Std  AUC Mean  \\\n",
      "RF            0.6503      0.0227         0.7914        0.0114    0.8591   \n",
      "SVM           0.5721      0.0395         0.7602        0.0208    0.8414   \n",
      "XGBoost       0.6665      0.0231         0.7819        0.0141    0.8508   \n",
      "DT            0.6572      0.0349         0.7657        0.0154    0.7479   \n",
      "LR            0.6190      0.0341         0.7777        0.0191    0.8399   \n",
      "NB            0.7715      0.0311         0.6965        0.0161    0.8059   \n",
      "\n",
      "         AUC Std  \n",
      "RF        0.0073  \n",
      "SVM       0.0148  \n",
      "XGBoost   0.0136  \n",
      "DT        0.0188  \n",
      "LR        0.0149  \n",
      "NB        0.0165  \n"
     ]
    }
   ],
   "source": [
    "# Exibir tabela de resultados\n",
    "print(\"\\nResultados:\")\n",
    "print(results_df.round(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
